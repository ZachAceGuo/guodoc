---
icon: lightbulb
---
# 面试每日题目
### day01

#### **ES 用来做什么**

做**全文搜索**、**日志分析**、**距离计算**。和 Logstash、Kibana 组成 ELK 做日志收集、展示。

#### **为什么用 ES**

MySQL 模糊查询慢，且模糊查询时索引会失效；ES 有**分词**、**相关性搜索**、**地理位置查询**，检索速度快

#### **ES 与 MySQL 如何保持一致**

MySQL 写入 → 产生日志 binlog → Canal 监听 → 发 MQ → 搜索服务收到后写 ES。

#### **ES 数据类型有哪些**

text、keyword；integer/long/float/double/boolean；date、binary、geo_point；object 等。

#### **ES采用什么数据结构**

1. **index（索引）**
   相当于 MySQL 的“库”。不同业务放不同索引，比如 Account、Book。

2. **mapping（映射）**
   相当于“表结构”。定义字段名、字段类型、是否分词、是否可搜索。

   `type`：字段数据类型，

   `index`：是否参与搜索

   `analyzer`：构建倒排索引时使用哪种分词器分词

   `search_analyzer`: 搜索时使用哪种分词器分词

   `properties`：该字段的子字段

3. **field（字段）**
   相当于“列”。文档中的单个属性。

4. **document（文档）**

   相当于“行”。一条完整的数据记录，用 JSON 表示。

### day02

#### **使用什么分词器**

我们主要用 **IK 分词器**，包括：
**ik_max_word**：细粒度，建索引用，尽可能多切词。
**ik_smart**：粗粒度，搜索用，更贴近用户意图。

其他常见分词器：
Standard（默认英文分词）、Smart Chinese Analyzer（官方中文）、Jieba（第三方中文）。

#### 倒排索引

倒排索引是一张“词 → 文档”的映射表。每个词条都会记录：在哪些文档出现、出现次数、出现位置。搜索时 ES 会先分词，再用词条去查这张表，直接拿到文档 ID，因此速度非常快。

构建流程可以理解成“三步一落”：
先把文档切词 → 去掉无意义的停用词 → 统计词频、位置 → 最终生成“词 → 文档列表”的倒排表。

查询时的动作也很简洁：
解析用户输入 → 按关键词查倒排索引 → 给匹配文档打分（BM25 之类的相关性算法） → 按相关度排序返回。

#### 正排索引/正向索引

正排索引（Forward Index）是 **“ID → 文档内容”** 的映射。查询时要先找出文档，再把搜索词和文档内容逐个对比，看是否包含关键词，所以速度远慢于倒排索引。

#### ES的分词策略是什么

构建倒排索引时 使用ik_max_word，即 插入数据到es的时候，使用ik_max_word最细粒度；

搜索的时候 使用ik_smart 智能分词（最粗粒度）

1. 创建的时候希望更多的词条能够关联到某个文档，这样在搜索的时候更有可能被检索到
2. 搜索的时候希望更加能够贴近用户的搜索期望，而不要分词太细

#### 深度分页

针对深度分页，elasticsearch提供了两种解决方案：

- `search after`：分页时需要排序,第二次查询时候携带上一次查询的排序值作为 search_after的值就可以了；原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。
- `scroll`滚动查询：原理将排序后的文档id形成快照，保存下来，基于快照做分页。官方已经不推荐使用。

### day03

#### Redis的作用、使用场景

- 可以用作缓存
- 存放token令牌
- 发送登录时候的，短信验证码可以存放到redis
- 分布式锁

#### 常见五种数据类型及结构

string字符串，list列表，set集合，zset，hash哈希，

#### 除了常见的五种类型还有哪些

除了常见的字符串、哈希、列表、集合、有序集合外，Redis 还有：

1. **位图（Bitmaps）**：基于字符串操作的位数组，常用于统计和用户行为跟踪。
2. **超日志** **（HyperLogLog）**：概率数据结构，估算集合基数，内存占用极低。
3. **地理空间索引（Geospatial Indexes）**：存储坐标，支持距离查询（GEOADD、GEORADIUS）。
4. **流（Streams）**：消息队列结构，支持消费组和消息确认。
5. **JSON 支持**（RedisJSON 模块）：原生存储和操作 JSON 数据。

#### **缓存问题三兄弟——缓存雪崩**

**缓存雪崩**：大量缓存同时失效，导致数据库瞬时高负载。

**解决方案**：如果是宕机使用集群，如果是过期给不同缓存设置**错开过期时间**，避免集中失效。

#### 缓存问题三兄弟——**缓存穿透**（不存在的数据）

**缓存穿透**：请求不存在的数据，频繁打到数据库。
**解决方案**：

1. **布隆过滤器**：先判断数据是否存在，不存在直接拦截。
2. **缓存空结果**：把空结果缓存一段短时间，避免重复查询。

#### 缓存问题三兄弟——缓存击穿

**缓存击穿**：热点 key 过期时，大量请求直接打到数据库。
**解决方案**：

1. **加锁**：更新缓存时加锁，其他请求等待。
2. **异步预热**：提前加载热点数据到缓存。
3. **逻辑过期**：热点 key 不设置过期，到期后手动删除。

#### 布隆过滤器的实现，怎么用

**布隆过滤器**：用位图 + 多哈希函数判断元素是否存在。
**实现原理**：

- 插入：多个哈希函数计算位置，设置对应位为 1。
- 查询：检查所有对应位是否为 1；若有 0，则元素不存在；若全 1，则可能存在（有误判）

### day04

#### Redis为什么快

**全内存操作**：数据存储在内存中，访问速度极快。

**单线程架构**：避t6

**异步 I/O 多路复用**：通过 epoll 等技术高效管理大量并发连接。

#### Redis是单线程的吗

Redis 6.0之前是单线程；Redis 6.0+ 特性：

- **网络 I/O 多线程**：读写请求的网络处理可多线程加速。
- **核心命令执行仍单线程**：数据操作和命令逻辑保持单线程，保证原子性和简单锁机制。

### day05

#### Redis宕机怎么办

查看 Redis 的日志文件，通常位于 /var/log/redis/ 或通过配置指定的位置，寻找任何错误信息或警告。

**内存不足**：Redis 是内存数据库，如果内存耗尽，可能会导致 Redis 崩溃。

**配置错误**：不正确的配置可能导致 Redis 无法正常启动或运行。

**硬件故障**：如服务器硬件问题（磁盘、网络等）。

为了让redis更加可靠；我们会搭建Redis的 哨兵（3个节点） + 主从（1主2从）的方式保障其的高可用。

#### Redis有哪些集群

**主从集群**：主节点与从节点的数据是一模一样的，不能实现故障转移

**哨兵+主从**：当某个主节点宕机且哨兵的的主观下线超过一半的话就会选举新的主节点，实现了自动的故障转移，写并发能力没有提升，存储容量没有提升

**分片集群**：Redis各个集群节点的数据是不一样的，可以有多个master节点，每个master都可以提供写操作：写操作并发能力提升了

每个master还可以有多个slave，可用性更强，并且读操作并发能力也更强了

每个master存储的数据是不同，通过**CRC16算法**对数据的key做哈希计算，最终计算的结果一定是**0~16383**，增加master就增加了存储的容量

连接任意一个master，都会帮我们自动重定向到正确的master上进行存取操作

#### Redis主从复制

- `slave`节点请求增量同步
- `master`节点判断`replid`，发现不一致，拒绝增量同步
- `master`将完整内存数据生成`RDB`，发送`RDB`到`slave`
- `slave`清空本地数据，加载`master`的`RDB`
- `master`将`RDB`期间的命令记录在`repl_baklog`，并持续将log中的命令发送给`slave`
- `slave`执行接收到的命令，保持与`master`之间的同步

#### Redis数据持久化策略

Redis 提供了两种主要的数据持久化策略：RDB和 AOF

**RDB** 会将Redis内存中的数据通过快照形式持久化保存到磁盘文件上，这是一个二进制文件。默认触发快照写的策略有：

- 如果在过去900秒（15分钟）内至少有1个键发生变化，则触发一次快照。
- 如果在过去300秒（5分钟）内至少有10个键发生变化，则触发一次快照。
- 如果在过去60秒内至少有10000个键发生变化，则触发一次快照。

**AOF** 将Redis执行的 **写命令** 追加保存到**只读的日志文件**磁盘文件上 中。重启时，Redis 会重新执行这些命令以恢复数据状态。

**AOF的写回策略**：

- **每秒fsync** (`everysec`)：默认情况下，每秒一次将缓冲区的内容同步到磁盘。这种模式提供了较好的性能和安全性之间的平衡。
- **每次写入fsync** (`always`)：每次写命令都会立即同步到磁盘，确保最高的数据安全性，但会对性能产生较大影响。
- **从不fsync** (`no`)：依赖操作系统来决定何时将缓冲区内容刷新到磁盘，虽然提高了性能，但增加了数据丢失的风险。

**重写机制**：

- **AOF 重写**：为了防止 AOF 文件变得过大，Redis 支持 AOF 重写功能，即在不影响现有数据的前提下，压缩冗余的命令序列。重写过程是在**子进程中完成**的，**不会阻塞主进程**。

我们项目的话；会使用RDB和AOF混合持久化的模式；在这种模式下，AOF 文件不仅包含所有写命令，还会定期插入 RDB 快照作为基准点。这使得 AOF 文件更加紧凑，并且可以在启动时更快地加载数据。

#### 过期key处理策略

- **惰性删除**：Redis会在每次访问KEY的时候**判断当前KEY有没有设置过期时间**，如果有，过期时间是否已经到期；过期的话则删除。
- **周期删除**：通过一个定时任务，周期性的**抽样**部分过期的key，然后执行删除。

### day06

#### 内存淘汰策略

Redis支持8种不同的内存淘汰策略：

- `noeviction`： **不淘汰任何key**，但是**内存满时不允许写入新数据**，默认就是这种策略。
- `volatile-ttl`： 对**设置了TTL的key**，比较key的剩余TTL值，**TTL越小越先被淘汰**
- `allkeys-random`：对全体key ，**随机进行淘汰**。也就是直接从db->dict中随机挑选
- `volatile-random`：对设置了TTL的key ，**随机进行淘汰**。也就是从db->expires中随机挑选。
- `allkeys-lru`： 对全体key，**基于LRU算法**进行淘汰
- `volatile-lru`： 对设置了TTL的key，**基于LRU算法**进行淘汰
- `allkeys-lfu`： 对全体key，**基于LFU算法**进行淘汰
- `volatile-lfu`： 对设置了TTL的key，**基于LFU算法**进行淘汰

比较容易混淆的有两个算法：

- **LRU**（**`L`**`east`**`R`**`ecently`**`U`**`sed`），最近最久未使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。
- **LFU**（**`L`**`east`**`F`**`requently`**`U`**`sed`），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。

#### 分布式锁

分布式锁是一种用于在**分布式系统中保障多个进程或线程**对**共享资源正确访问的一种机制**。也就是说分布式锁要确保在不同节点或说系统上的进程不会同时访问或修改同一资源。

在redis中可以使用 `setNX + 过期时间` 的方式来实现分布式锁。

> 使用set命令也可以实现分布式锁
>
> 如果要使用set命令则： `SET key value NX PX timeout` 来尝试设置一个键，并指定超时时间（以毫秒为单位）。`NX` 表示只有当键不存在时才执行此操作，确保了锁的唯一性。PX 是 **告诉 Redis：后面这个数字的单位是毫秒**。

我们项目中使用的是**redisson实现**的，它是使用 **Redis 的** **Hash** **数据类型** 来存储和管理锁

#### 分布式锁使用场景

- 支付（**防止并发时订单的重复提交**，多次刷新导致的重复支付）
- 订单下单的时候，对商品库存进行加锁；**防止超卖**

#### Redisson的好处/优势

**1.** **分布式锁**

- Redisson 提供分布式锁功能。比如：**使用 `RLock` 可以确保分布式环境下的多个进程或者线程互斥访问资源**。

**2.** **分布式集合和数据结构**

- Redisson **提供了 Redis 支持的集合数据结构的分布式实现**，比如：
    - `RMap`（分布式 Map）
    - `RList`（分布式 List）
    - `RSet`（分布式 Set）
    - `RQueue`（分布式队列）
- **这些数据结构本身就有很好的并发性能，可以方便地在分布式系统中共享数据**。

**3.** **高可用性和故障转移**

- Redisson 能够与 Redis Sentinel 和 Redis Cluster 配合使用，支持高可用性和故障转移机制。即使 Redis 实例宕机，Redisson 可以自动重新连接到新的主节点，保证应用的持续运行。

**4.** **异步和响应式编程**

- Redisson 支持异步编程，可以通过使用 `RFuture` 和 `CompletableFuture` 提高并发性能。

**5.** **原子操作**

- Redisson 支持对 Redis 数据的原子操作，确保了操作的事务性和一致性。例如，可以在一个操作中同时执行多个 Redis 命令，而不必担心中间的竞态条件

#### Redisson看门狗

Redisson 的**看门狗**（**Watchdog**）是一个用于自动延长分布式锁过期时间的机制，**主要解决在分布式环境下，持有锁的客户端在执行任务时出现故障或崩溃的情况，防止其他客户端长时间等待锁释放。**看门狗的机制通过自动刷新（默认30秒过期时间，**每隔10秒会自动续期到30秒**，从而保持分布式锁不过期）锁的过期时间，确保锁在任务执行过程中始终保持有效。

追问：如果自动续期会不会导致一直不释放锁而产生死锁？

- 业务正常处理的话，是会释放锁的
- 如果业务不正常，我们也有异常处理，在finally里面会释放
- 如果是业务宕机，那么分布式锁也有过期时间，默认是30秒；所以怎么样都不会死锁

### day07

#### Redis如何处理并发的

通过 **单线程模型** 处理：具体

- **核心处理逻辑**：Redis 的所有读写操作都在一个单独的线程中顺序执行，避免了多线程环境下的锁竞争问题。这种设计简化了并发控制，并提高了性能。
- **非阻塞 I/O**：尽管是单线程，但 Redis 使用事件驱动的 I/O 多路复用技术（如 epoll 或 kqueue），可以同时处理大量客户端连接而不被阻塞。

#### Redis的管道

Redis管道是一种批量处理机制，它让客户端能够将多个命令打包成一个请求发送给 Redis 服务器。服务器接收到这个请求后，会依次执行这些命令并将结果一并返回给客户端。

#### Redis怎么存储一个对象

将对象序列化为 JSON 格式的字符串，然后作为普通的 Redis 字符串进行存储。

#### Redis 和数据库的数据一致性如何保证

如果要求强一致：可以采用**同步双写并加锁**的方式保证一致

如果要求最终一致：

- 方式一：可以采用**定时任务定时更新缓存**；但这种情况通常会有一段时间不一致。
- 方式二：也可以采用在**更新数据库后 直接删除缓存**
- 我们项目的门户首页里，这两种方式都用到了；更新数据时删缓存能保证**较强的一致性**，然后使用**定时任务**作为一致性的**兜底方案**

另外还有：**延迟双删**，我们项目中没有使用到（因为等待时间无法确定）

1. **第一次删除缓存**
    - 当要更新数据库时，先删缓存，防止其他请求读到旧数据。

2. **更新数据库**
    - 执行真正的数据更新操作。

3. **延时等待**

    - 等待一个短时间（比如几百毫秒到几秒），让可能同时访问缓存的请求都结束。
    - 这主要防止“数据库更新前，有请求又把旧数据写回缓存”。

4. **再次删除缓存**

- 确保缓存里没有旧数据，保证下一次读取时一定是数据库最新数据。

#### Redis的默认内存大小

Redis 的默认内存通过 **maxmemory** 设置；**大小为 64MB** 可以修改。如果超出的话，那么会抛出异常。

#### 红锁RedLock

**RedLock** 是 Redisson 提供的一种分布式锁算法，主要作用是解决**在多个 Redis 实例上执行加锁**，如果发生了单个 Redis 节点故障时仍**能保证锁的可用性和一致性**的解决方案。它的主要实现**思想是在多个 Redis 实例之间进行协作来确保锁的一致性和高可用性**。

RedLock 的实现流程如下：

1. **多个 Redis 实例**：至少需要 5 个独立的 Redis 实例部署在不同的机器或节点上，来确保高可用性。
2. **获取锁的过程**：
    1. **客户端尝试在每个 Redis 实例上获取锁。**客户端会依次向每个 Redis 节点发送请求，会尝试在每个节点上设置锁，并且记录每次请求的时间。
    2. 只有当锁在 **多数** Redis 实例（至少 3 个 Redis 节点）上成功设置，且整个过程在一个合理的时间窗口内完成时，才认为锁被成功获取。
3. **获取锁的条件**：
    1. 客户端必须在短时间内（通常是毫秒级别）向多个 Redis 节点请求并成功获得锁。
        -   这个过程需要保证：

        -   **锁的设置时间不会过长**（避免单点故障）。
        -   客户端必须**至少成功获取到大多数 Redis 节点**上的锁（通常是 3 个节点及以上）。
        -   锁的获取操作**必须具备足够的时间容忍度**。
4. **释放锁**：
    1. 客户端获取锁后，在完成任务时，客户端会从它成功获取锁的 Redis 节点上释放锁。
    2. 释放锁时，**需要检查当前客户端是不是还持有锁，避免误释放锁**。

### day08

#### SpringBoot自动装配原理

1. **启动应用**：当应用启动时，Spring Boot 会解析 `@SpringBootApplication` 注解。

> @SpringBootApplication 是一个复合注解，它包含了以下三个注解：
> @Configuration：标记当前类为配置类。
> @EnableAutoConfiguration：启用自动装配。
> @ComponentScan：扫描并注册带有 @Component 注解的类。

2. **加载配置**：`@EnableAutoConfiguration` 注解会触发自动配置机制，**加载 `spring.factories` 文件中列出的自动配置类。**
3. **条件注解**：Spring Boot 会加载 `spring.factories` 文件中每个`自动配置类`上的条件注解，**来判断是否应用这个配置**。

> 自动配置类 通常使用条件注解（如 `@ConditionalOnClass`、`@ConditionalOnMissingBean`、`@ConditionalOnProperty` 等）来控制是否应该应用某个配置。这些条件注解确保只有在满足特定条件时才会加载和应用相应的配置。

4. **应用配置**：**符合条件的自动配置类会被加载注册到IOC容器并应用**，这样实现自动配置相应的组件和服务。

> 注册到IOC容器之后；就可以在其它的Bean中通过 @Resource 或 @Autowire 注入并使用

#### Spring怎么解决循环依赖/三级缓存

Spring使用了一种称为“延迟解析”的策略来**解决循环依赖问题**。也被称为使用三级缓存来解决循环依赖问题的：

当Spring容器初始化时，它会先实例化Bean（但不会调用其初始化方法），然后将Bean放入一个临时的Map中。

**当一个Bean请求另一个Bean作为其依赖时，Spring会首先检查这个临时Map中是否有已经实例化但未完全初始化的Bean。**

如果有，就会直接返回这个Bean的引用，从而解决了循环依赖问题。

追问：三级缓存的话：

Spring 使用三级缓存机制来解决循环依赖问题。这三级缓存分别是：

1. **一级缓存（Singleton Cache）**：存放完全初始化好的单例 Bean。**(完全初始化好的 bean)**
2. **二级缓存（Early Singleton Cache）**：存放尚未完全初始化的 Bean，这些 Bean 已经完成了构造函数的调用，但还没有调用初始化方法。**(保存半成品 bean)**
3. **三级缓存（Prototype Cache）**：存放原型 Bean 的缓存，与循环依赖无关，主要用于提高原型 Bean 的创建效率。**(BeanFactory)**

#### Spring的IOC

**IOC（控制反转）**主要是用于减少代码间的耦合度。通过 IOC，对象的创建和管理**不再由程序代码直接控制**，而是交给外部容器（如 Spring 容器）来管理。这样的话，对象之间的**依赖关系可以通过配置文件或注解来声明**，而不是硬编码在程序中。

#### Spring的AOP

AOP（Aspect-Oriented Programming，面向切面编程）是一种编程范式，用于通过预定义的规则或切面对横切关注点（cross-cutting concerns）进行模块化，统一添加不同的业务逻辑。常见的应用场景包括日志记录、事务管理、安全控制、性能监控等

AOP 使得这些横切关注点与核心业务逻辑解耦，从而提高代码的可维护性、可重用性和可扩展性。

> 如果问到动态代理，则查看第一章中的动态代理实现

**核心概念**：

- 切面（Aspect）：一个模块，定义了横切关注点的实现，比如日志记录、事务管理等。切面可以包含一个或多个增强（Advice）。
- 连接点（Join Point）：程序执行过程中的一个特定点，通常是方法的调用。Spring AOP 中的连接点是方法执行时。
- 通知（Advice）：在特定的连接点执行的代码，包含了具体的横切逻辑。通知有几种类型：
    - Before：在目标方法执行之前执行。
    - After：在目标方法执行之后执行（无论方法是正常执行还是抛出异常）。
    - After-throwing：如果目标方法抛出异常时执行。
    - After-returning：如果目标方法成功返回时执行。
    - Around：在目标方法执行前后执行，可以控制目标方法的执行，甚至可以完全拦截目标方法的执行。
- 切入点（Pointcut）：定义了在哪些连接点上执行通知。切入点通过表达式来定义，比如可以指定某些方法或类上的方法需要应用通知。
- 目标对象（Target Object）：被代理的对象，通常是被 AOP 拦截的业务类。

**切面**定义“增强”，**连接点**是“可插入增强的时刻”，**通知**是“实际增强的动作”，**切入点**是“动作应用的规则”，**目标对象**是“被增强的业务”。

**切面（Aspect）**它**封装了横切逻辑**，和核心业务是分开的，**包含一个或多个增强**         `LoggingAspect` 这个类。

**连接点（Join Point）** **每个方法调用都是一个潜在的连接点**，可以插入增强逻辑。    `placeOrder()` 方法执行的这个时刻。

**通知（Advice）**它们就是**实际执行的增强操作** Before After`logBefore()` 和 `logAfter()` 方法。

**切入点（Pointcut）**它**定义了哪些方法需要应用增强逻辑的通知** `@Pointcut("execution(* com.example.demo.OrderService.*(..))")`

**目标对象（Target Object）**被代理的对象，通常是被 AOP 拦截的业务类。

```java
// 1. 目标对象（被增强的方法）
@Service
public class OrderService {

    public void placeOrder(String item) {
        System.out.println("下单成功: " + item);
    }
}

// 2. 切面（增强的方法）
@Aspect
@Component
public class LoggingAspect {

    // 切入点：所有 OrderService 的方法
    @Pointcut("execution(* com.example.demo.OrderService.*(..))")
    public void orderMethods() {}

    // 前置增强：方法执行前打印日志
    @Before("orderMethods()")
    public void logBefore(JoinPoint joinPoint) {
        System.out.println("准备调用方法: " + joinPoint.getSignature().getName());
    }

    // 后置增强：方法执行后打印日志
    @After("orderMethods()")
    public void logAfter(JoinPoint joinPoint) {
        System.out.println("方法调用完成: " + joinPoint.getSignature().getName());
    }
}

```

### day09

#### AOP失效的场景有哪些

第一类是**自我调用**。**类内部方法直接调用同类的另一个方法**，这种调用不会经过代理，自然也触发不了切面。原因是 **Spring 基于代理机制**，**只拦截代理对象的外部调用**。通常我们会**通过代码拆分**，或者使用 AspectJ 的方式解决。

第二类是**方法级别的访问权限问题**。**私有方法、静态方法**，甚至部分默认访问级别的方法，Spring AOP 都无法增强。主要原因是**私有方法无法被代理访问，静态方法属于类级别**，**也不参与实例代理**。因此在需要增强的逻辑里，我们一般会**保持方法为 public**。

第三类是**绕过代理的实例化方式**。如果业务代码里**直接 new 出对象**，**而不是通过 Spring 容器管理获取的 Bean**，那么这个对象本身就没有代理，自然不可能触发切面。整体要求是所有目标类必须交给容器管理。

第四类是**配置问题**。**切点表达式不匹配、AOP 功能未开启、依赖注入异常**，都可能导致切面逻辑不执行。通常需要检查**是否开启 AspectJ 自动代理**、**切点是否精确命中目标方法。**

Spring AOP 失效场景及其原因：

1. **自我调用问题**

    - **描述**：当一个类中的方法内部调用了同一个类的另一个被代理的方法时，AOP 代理不会拦截这个内部调用。

    - **原因**：这是因为 Spring AOP 默认使用的是基于代理的机制（JDK 动态代理或 CGLIB）。在这种情况下，只有通过代理对象进行的方法调用才会被拦截。对于同一对象内的直接方法调用，不会经过代理，因此 AOP 切面不会生效。

    - **解决方案**：可以通过重构代码来避免这种情况，例如将需要拦截的方法移到不同的类中；或者使用 AspectJ 编译时织入来处理自我调用的问题。

2. **私有方法**

    - **描述**：Spring AOP 不会拦截私有方法。

    - **原因**：由于 Java 的访问控制规则，私有方法不能被外部类（包括代理类）访问，因此 AOP 框架无法为这些方法创建代理。

    - **解决方案**：如果确实需要对私有方法应用 AOP，可以考虑将其改为受保护（`protected`）或包级私有（默认访问级别），然后再根据具体需求调整设计。

3. **静态方法**

    - **描述**：Spring AOP 也无法拦截静态方法。

    - **原因**：静态方法属于类级别的成员，不属于任何实例对象。而 Spring AOP 主要是针对对象实例的方法调用进行增强的，所以它不能应用于静态方法。

    - **解决方案**：避免在需要 AOP 增强的地方使用静态方法，或者寻找其他方式实现类似的功能。


4. **非公共方法**

    - **描述**：除了私有方法外，非公共但不是 `protected` 的方法（即默认访问级别）也可能不会被正确拦截。

    - **原因**：这取决于具体的代理机制。JDK 动态代理只支持公共接口的方法，而 CGLIB 代理则可以处理更多类型的方法，但仍有一些限制。

    - **解决方案**：尽量确保需要 AOP 增强的方法是公开的（`public`），以保证兼容性。

5. **绕过代理**

    - **描述**：如果直接通过 `new` 关键字创建了一个目标对象而不是通过 Spring 容器获取，则这个对象不会被 AOP 代理所包装，因此其上的 AOP 切面也不会生效。

    - **原因**：Spring AOP 是基于 Spring 容器管理的对象（Bean）工作的。只有那些由容器创建和管理的对象才会受到 AOP 规则的影响。


- **解决方案**：始终从 Spring 应用上下文中获取 Bean 实例，而不是自行实例化它们。


6. **错误配置**

    - **描述**：如果 AOP 配置不正确，例如切入点表达式写错、缺少必要的依赖注入等，也会导致 AOP 不起作用。

    - **原因**：配置错误会导致 Spring 无法正确识别哪些方法应该被增强，或者根本就没有启动 AOP 支持。


- **解决方案**：仔细检查 AOP 配置文件（XML 或注解），确保所有设置都是准确无误的，并且已经启用了 AOP 支持（例如通过 `<aop:aspectj-autoproxy/>` 或 `@EnableAspectJAutoProxy` 注解）。


#### 事务的传播行为

在 Spring 的事务传播机制里，**核心思想就是**——**当一个方法被事务管理时，另一个方法再调用它，这两个事务之间该怎么协作**。Spring 一共提供了七种传播行为，我重点按语义来讲。

首先是需要有事务(默认)。它的策略是“**有事务就加入，没有就自己开一个**”。这个适用于大多数情况。

第二类是支持事务，可有可无的。**有事务会加入，如果没有，它就直接以非事务方式运行。**常**用于读操作**，对一致性要求不高。

第三类必须要有事务，没有就抛出异常，**有事务会加入；如果当前没有事务，则抛出异常**。通常用于必须依赖事务上下文的逻辑。

第四个是起一个新事务创建一个新的事务，**如果当前存在事务，则将当前事务挂起**，适用于那些需要独立事务的操作

第五个不需事务内运行，有则挂起，**以非事务方式执行操作，如果当前存在事务，则将当前事务挂起**，适用于那些不应该在事务中执行的操作

第六个是非事务方式执行，**以非事务方式执行操作，如果当前存在事务，则抛出异常**，适用于那些绝对不能在事务中执行的操作

第七个是嵌套事务，**如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则创建一个新的事务**。用于那些需要在一个更大的事务中执行部分操作

Spring 定义了七种主要的事务传播行为：

1. **REQUIRED-需要有事务**（默认）
    - **描述**：如果当前存在事务，则加入这个事务；如果当前没有事务，则创建一个新的事务。
    - **适用场景**：最常见的场景，适用于大多数情况。
2. **SUPPORTS-支持事务，可有可无**
    - **描述**：如果当前存在事务，则加入这个事务；如果当前没有事务，则以非事务方式执行。
    - **适用场景**：适用于那些不需要事务支持的操作，但如果存在事务也不会影响结果的情况。
3. **MANDATORY-必须要有事务，没有就抛出异常**
    - **描述**：如果当前存在事务，则加入这个事务；如果当前没有事务，则抛出异常。
    - **适用场景**：适用于那些必须在事务中执行的操作，如果不在事务中执行则会失败。
4. **REQUIRES_NEW-起一个新事务**
    - **描述**：创建一个新的事务，如果当前存在事务，则将当前事务挂起。
    - **适用场景**：适用于那些需要独立事务的操作，即使在已有事务中也需要创建新的事务。
5. **NOT_SUPPORTED-不需事务内运行，有则挂起**
    - **描述**：以非事务方式执行操作，如果当前存在事务，则将当前事务挂起。
    - **适用场景**：适用于那些不应该在事务中执行的操作，例如查询数据库状态的操作。
6. **NEVER-非事务方式执行**
    - **描述**：以非事务方式执行操作，如果当前存在事务，则抛出异常。
    - **适用场景**：适用于那些绝对不能在事务中执行的操作。
7. **NESTED-嵌套事务**
    - **描述**：如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则创建一个新的事务。
    - **适用场景**：适用于那些需要在一个更大的事务中执行部分操作，但这些操作可以独立回滚的情况。

#### Spring事务失效

1. **在类里面**，使用没有事务控制的方法 调用有事务控制的方法：
    - **总结**：内部方法调用不会触发事务管理，因为事务管理是基于代理的。
2. 在事务控制的方法内部，如果将**异常捕获而且不抛出**的话；不会进行正常的回滚，也属于事务失效
    - **总结**：捕获异常但不重新抛出会阻止事务管理器检测到异常并回滚事务。
3. 事务方法**不是使用public 修饰符**的话，也会导致事务失效：
    - **总结**：`@Transactional` 注解只能作用于 public 方法。
4. 如果调用事务方法的实例；是**使用了 `new` 关键字手动创建的**，也会导致事务失效：
    - **总结**：**手动创建 Bean 会绕过 Spring 容器**，导致事务管理失效。
5. **使用了错误的事务传播行为**：
    - **总结**：某些事务传播行为（如 `NOT_SUPPORTED`、`NEVER`）会禁用事务管理。

#### Spring中Bean的加载流程

**首先是读取和解析配置文件**，**接下来框架会准备一个 BeanFactory**，这是整个 IoC 的核心，用来管理 Bean 的创建和生命周期。

配置读完之后，会**把每个 Bean 的元信息**，**也就是 BeanDefinition**，**注册到容器里**，但此时 Bean 还没有真正实例化。紧接着调用**BeanFactoryPostProcessor**。这类处理器允许在 Bean 实例化之前，对 BeanDefinition 做修改

**随后才进入真正的 Bean 创建阶段**。**Spring 会根据 BeanDefinition 去实例化对象**，并在**实例化后设置 Bean 的属性值**，然后调用**BeanPostProcessor**，它允许开发者在初始化前后做增强，比如 AOP 的代理就是在这里生成的。

然后是**调用初始化方法**。到这一步，Bean 才算完全就绪，可以被容器使用和注入。

最后，**在容器关闭时**，**会调用销毁方法**，对资源进行清理。

Spring 中 Bean 的加载流程可以概括为以下几个主要步骤：

1. **读取配置**：读取和解析配置文件。
2. **创建 BeanFactory**：创建 `BeanFactory`。
3. **注册 BeanDefinition**：注册 Bean 定义。
4. **初始化 BeanFactoryPostProcessors**：调用 `BeanFactoryPostProcessor`。
5. **实例化 Bean**：创建 Bean 实例。
6. **设置属性值**：设置 Bean 的属性值。
7. **初始化 BeanPostProcessors**：调用 `BeanPostProcessor`。
8. **调用初始化方法**：调用初始化方法。
9. **使用 Bean**：Bean 初始化完成后可以被使用。
10. **销毁 Bean**：容器关闭时调用销毁方法。

### day10

#### RabbitMQ在哪用到了/场景

用户在**小程序里搜索服务**时，**需要提前将服务信息同步到ES**，用到了RabbitMQ

**历史订单的冷热分离**时，将**完成15日的订单迁移到历史订单库**时，用到了RabbitMQ

**订单过期时自动取消订单**，用到了RabbitMQ的延迟消息

**支付服务向业务服务通知支付结果时**

#### 消息重复消费/幂等

1、**发送消息的时候，携带消息Id**；

2、**消费者接收消息**的时候，**先根据消息id到数据库**（mysql，redis都可以）中的 **去重表**（`主键、消息id、消息内容，接收时间，处理时间，处理状态`） **查询是否已经处理过这个消息**；

3、**如果处理过这个消息则什么都不做**，避免重复处理；

4、**如果没有这个消息说明还没处理过**，**保存消息到去重表 ；然后再处理消息**；**如果处理消息成功则更新去重表的状态为1**；**如果处理失败则可以采用定时任务**，定时对这个消息进行处理，**直到处理消息成功为止**。

#### 消息怎么可靠生产

我们会在**发送消息的时候**，**开启生产者重连机制**；并且**使用Confirm回调**和**Return回调**处理发送失败的消息，将失败消息记录到一张表里面；**启动定时任务**定时发送，**发送到成功为止**

**定时任务怎么做？**：

1. 首先**把消息数据写入数据库**，用**状态码来控制消息发送状态**。
2. **开启定时任务**，间隔时间比如3秒，**查询未发送的消息**。
3. **调用消息生产者**，**发送消息到MQ中间件**。
4. **消息生产者**，**设置confirmCallback确认回调对象**，**判断ack**

-- true:  消息发送成功，**修改消息发送状态为: 已发送**。

-- false: 消息发送失败。

#### 消息怎么可靠的消费

1、**消费者确认机制**；接收的时候，业务处理成功才返回ack

2、也会设置**消费者本地重试机制**；比如：在消费者端配置重试3次

3、如果**重试也失败的话**，就**按照消息回收策略**，**将消息重新发布到其它交换机**

4、如果**再不行**；那**就主动反向查询业务**，**在生产者这边直接查询消费者端的业务处理成功没有**（兜底方案）

#### RabbitMQ自身可靠

**所有的交换机、队列、消息都可以设置为持久化模式**（重启后还在）

**RabbitMQ可以做集群**，**实现镜像队列和仲裁队列**（即使RabbitMQ其中一个节点挂了；也还有其它节点提供服务；不仅如此，因为做了镜像或仲裁队列，所以交换机、队列、消息也都是不会丢失的，每个节点都会有副本。）

![图片1](./assets/image-20251127221302834-1764317814553-1.png)

### day11

#### 消息积压/堆积问题

1. **消息过多，消费者消费速度太慢。那么可以**
   - **增加多个消费者并发**消费
   - **每个消费者中使用多线程**并发消费
   - **设置消息存活时间(TTL)** Time To Live
   - **设置队列中存储消息的界限**(Lim) limit

2. **消费者消费失败，消息还在业务队列中。**
   - 再重试一次，如果**还不行，扔到死信队列，避免队列阻塞**。

#### 死信队列

当我们的**业务队列处理消息失败**(业务异常**重试次数达到上限**、**消息被拒绝**、**消息过期**、**队列已满**)，就会**将这些消息重新投递到一个新的队列**，**这个队列存储的都是处理失败的消息**，这个队列**就叫死信队列DLQ**(Dead Letter Queue)。

什么是死信？或者说为什么叫死信？因为这些消息大概是因为：

- **消息发送的时候被拒绝** (basic.reject or basic.nack)
- 或者 **消息过期 TTL**(Time To Live)
- 也可能是 **队列已满 消息进不了队列**；那这**些消息都被称为死信**

使用场景：只要是需要**发送延迟消息的地方都可以使用死信队列实现**；如：**清理垃圾附件、超时取消合同、超时支付**等

#### MQ的工作模式和交换机类型、核心概念

**MQ的工作模式**：简单队列模式、工作队列模式、fanout广播交换机、direct定向交换机、topic主题交换机、【headers请求头交换机交换机】

**核心概念**：连接Connection、通道Channel、交换机Exchange、队列Queue、绑定binding、消息Message

#### RabbitMQ的队列类型

临时队列、持久化队列、延时队列、死信队列、镜像队列、仲裁队列

#### RabbitMQ 中实现顺序消费消息

1、**基于单个队列+单线程消费实现顺序消费**

- **单队列模型：** 最直接的方式是使用一个队列来保证消息顺序。RabbitMQ 会按照生产者发送消息的顺序，将消息逐个传递给消费者。消费者使用单线程处理，会按照队列中的顺序来消费这些消息。确保消费者一个接一个地消费消息就可以保证顺序消费。

2、**使用消息的唯一标识符和分区**

如果有多组消息需要按顺序消费，但这些消息是独立的（例如：每组消息对应某个特定的用户、订单或其他对象），可以根据消息的分区键（例如：用户ID、订单ID等）将消息路由到不同的队列。

3、**配置** **`prefetch`** **参数**

在 RabbitMQ 中，`prefetch` 使得每个消费者一次只处理一个消息，从而保证了消息的顺序性。

### day12

#### SpringCloud使用到了哪些组件

Gateway，Nacos，OpenFeign，LoadBalancer（旧版本是Ribbon），阿里的Sentinel（旧版本是网飞公司的Histrix），Seata，还有RabbitMQ

如果他们特别问到是组件的话，那就说：Seata，Sentinel，Redis，RabbitMQ，XXL-JOB，ES

#### Spring，SpringBoot，SpringCloud的区别

- Spring 是基础框架，提供了所有的核心功能。核心是 IoC（控制反转） 和 AOP（面向切面编程）
- Spring Boot 是基于 Spring 的扩展，简化了应用的配置和部署，专注于单个应用的快速开发
   - 自动装配：Spring Boot 可以自动配置应用程序所需的组件，减少配置工作。
   - 内置服务器：Spring Boot 提供了内嵌的 Web 服务器（如 Tomcat、Jetty、Undertow）
   - 简化配置：通过 `application.properties` 或 `application.yml` 文件，可以灵活配置应用程序，而不需要在 XML 文件中进行繁琐的配置。
- Spring Cloud 是基于 Spring Boot 的微服务框架，专注在构建分布式系统和微服务架构。提供了对微服务生命周期、服务发现、配置管理、负载均衡、消息传递、熔断器等一系列功能的支持。

#### Spring Cloud和Spring Cloud alibaba 有什么区别

- **注册中心**: Spring Cloud 使用 Eureka 或 Consul，而 Spring Cloud Alibaba 推荐使用 Nacos。
- **配置中心**: Spring Cloud 使用 Spring Cloud Config，Spring Cloud Alibaba 同样推荐使用 Nacos。
- **网关**: Spring Cloud 使用 Zuul（逐渐被 Gateway 替代），Spring Cloud Alibaba 默认采用 Spring Cloud Gateway。
- **负载均衡**: Spring Cloud 使用 Ribbon 和 LoadBalancer，Spring Cloud Alibaba 支持这些同时也兼容阿里巴巴的产品。
- **熔断降级**: Spring Cloud 使用 Hystrix，而 Spring Cloud Alibaba 提供了 Sentinel 作为替代方案。
- **服务调用**: Spring Cloud 使用 Feign，Spring Cloud Alibaba 支持 OpenFeign。
- **分布式事务**: Spring Cloud 没有直接提供，通常依赖第三方方案如 2PC，而 Spring Cloud Alibaba 提供 Seata 解决方案。
- **消息中间件**: Spring Cloud 可以集成 RabbitMQ 等第三方组件，Spring Cloud Alibaba 推荐使用 RocketMQ。
- **分布式调度**: Spring Cloud 可能依赖外部工具如 xxl-job，而 Spring Cloud Alibaba 提供 SchedulerX。
- **短信平台**: Spring Cloud 没有直接提供，Spring Cloud Alibaba 提供 Alibaba Cloud SMS。

#### 负载均衡策略

Ribbon或其它负载均衡器的的负载均衡策略有：

**RoundRobinRule（轮询）**

- 这是默认的负载均衡算法，按照顺序循环选择服务器。

**RandomRule（随机）**

- 随机选择一个服务器实例。

**WeightedResponseTimeRule（加权响应时间）**

- 根据每个服务器的平均响应时间计算权重，响应时间越长权重越小，被选中的几率也越小。

**RetryRule（重试）**

- 先按照 RoundRobinRule 获取服务实例，如果获取失败，则在指定的时间间隔内重试。

#### Nacos服务注册与发现

Nacos是一个服务注册与发现的组件，用在分布式微服务系统间作为注册中心。服务的注册与发现的流程如下：

- 服务启动时就会注册自己的服务信息（服务名、IP、端口）到注册中心
- 调用者可以从注册中心订阅想要的服务，获取服务对应的实例列表（1个服务可能多实例部署）
- 调用者自己对实例列表负载均衡，挑选一个实例
- 调用者向这个实例发起远程调用

当服务提供者的实例宕机或者启动新实例时，调用者如何得知呢？

- 服务提供者会定期向注册中心发送请求，报告自己的健康状态（心跳请求）
- 当注册中心长时间收不到提供者的心跳时，会认为这个实例宕机，将其从服务的实例列表中剔除
- 当服务有新实例启动时，会发送注册服务请求，其信息会被记录在注册中心的服务实例列表
- 当注册中心服务列表变更时，会主动通知微服务，更新本地服务列表

#### Nacos 心跳机制

Nacos 通过**心跳机制**来实时监控服务实例的健康状态。当服务实例出现问题（如宕机、网络中断、负载过高）时，Nacos 会根据心跳超时规则快速发现并更新服务实例的状态。

- 服务实例：启动后向 Nacos 注册自己，并周期性**每隔5秒**发送心跳信息到nacos。
   - 心跳信息是使用http的put请求发送，包括：服务名称、IP、端口、集群名称、权重、是否为临时实例等
- Nacos 服务端：接收心跳，如果 Nacos 在 **15 秒**内（也就是3 次心跳）没有收到心跳，将实例标记为 不健康。如果连续 **30 秒**（6 次心跳）未收到心跳，Nacos 将该实例从服务列表中 删除（Deregister）

#### Gateway用来做什么

**作用**：路由与鉴权，以外还有如下的一些作用：

路由：路由是API网关很核心的模块功能，此模块实现根据请求，锁定目标微服务并将请求进行转发。

限流：实现微服务访问流量计算，基于流量计算分析进行限流，可以定义多种限流规则。

缓存：数据缓存。

日志：日志记录。

监控：记录请求响应数据，api耗时分析，性能监控。

鉴权：权限身份认证。

在网关怎么路由的； 回答配置 `routes `节点下配置 `id`、`uri`、`predicates`：

```YAML
spring:
  application:
    name: gateway
  cloud:
    nacos:
      server-addr: 192.168.12.168:8848
    gateway:
      routes:
        - id: item # 路由规则id，自定义，唯一
          uri: lb://item-service # 路由的目标服务，lb代表负载均衡，会从注册中心拉取服务列表
          predicates: # 路由断言，判断当前请求是否符合当前规则，符合则路由到目标服务
            - Path=/items/**,/search/** # 这里是以请求路径作为判断规则
```

### day13

#### 令牌桶、漏桶、滑动窗口

1. **令牌桶（Token Bucket）**

**令牌桶**算法用于控制请求的流量，允许在一定时间内突发流量，但也会限制整体流量的平均速率。其基本原理如下：

- **令牌的产生**：系统按固定的速率（如每秒生成一定数量的令牌）生成令牌，这些令牌放入一个桶中。
- **桶的容量**：桶有最大容量限制，当桶满时，新生成的令牌将被丢弃。
- **请求的处理**：每次请求到达时，如果桶里有令牌，允许该请求通过，并从桶中取走一个令牌。如果桶里没有令牌，则拒绝该请求，或者根据策略延迟请求。

2. **漏桶**算法通过模拟一个漏水的桶来实现限流。其基本原理如下：

- **请求进入桶中**：每个请求到达时都会进入桶中。
- **桶的容量**：桶有一个固定的容量限制，桶一旦满了，后续的请求就会被丢弃。
- **漏桶的漏水速率**：桶里的请求以固定的速率（与请求的处理速率相同）流出。也就是说，不管桶中积累了多少请求，桶的处理速度是恒定的。

3. **滑动窗口（Sliding Window）**

**滑动窗口**算法是对请求进行时间窗口切割的一种限流算法。它将时间划分为多个小时间片段，采用一个滑动的时间窗口来限制请求数量。其基本原理如下：

- **时间窗口**：将时间划分为固定大小的窗口（如1秒、1分钟等），并记录每个窗口内的请求数。
- **滑动窗口**：每当请求到达时，都会检查当前时间所在的窗口，如果该窗口内的请求数未超过设定的最大限制，允许请求通过；如果超过，则拒绝请求。
- **滑动**：随着时间的推移，窗口会向前滑动，过期的请求将从窗口中移除，新的请求会进入当前窗口。

#### Eureka与Nacos区别

Eureka和Nacos的区别有：

- Eureka的心跳是30秒一次，Nacos则是5秒一次
- Eureka如果90秒未收到心跳，则认为服务疑似故障，可能被剔除。Nacos中则是15秒超时，30秒剔除。
- Eureka每隔60秒执行一次服务检测和清理任务；Nacos是每隔5秒执行一次。
- Eureka只能等微服务自己每隔30秒更新一次服务列表；Nacos即有定时更新，也有在服务变更时的广播推送
- Eureka仅有注册中心功能，而Nacos同时支持注册中心、配置管理
- Eureka和Nacos都支持集群，而且默认都是AP模式

> Nacos默认注册的实例都是 临时实例；如果要成为非临时实例也就是永久实例（CP模式）的话；需要在配置中明确指定`ephemeral`字段为`false`。例如，在Spring Cloud中可以通过`spring.cloud.nacos.discovery.ephemeral=false`来实现。

#### Nacos热更新

在需要动态修改的配置值所在的类上方添加 `@RefreshScope` 注解；

或者 通过 `@ConfigurationProperties` 实现配置类。

#### Seata使用场景

- **下单时核销优惠券**
- **取消订单时退还优惠券**

#### Seata的模式

Seata 支持的主要模式：

1. **AT 模式**（Automatic Transaction）

AT 模式是 Seata **默认支持的分布式事务模式**，它通过 AOP（面向切面编程）的方式，对数据库操作进行拦截，并自动生成全局事务的分支事务。

- **特点**:
    - **对业务代码无侵入性**，只需要在业务方法上添加 `@GlobalTransactional` 注解即可开启全局事务。
    - 基于 SQL 解析实现，自动解析并生成回滚日志。
    - 支持 MySQL、Oracle、PostgreSQL 等多种主流关系型数据库。

2. **TCC 模式**（Try-Confirm-Cancel）

**TCC 模式要求业务方为每个参与分布式事务的服务定义三个接口：**`try`、`confirm` 和 `cancel`。

- **特点**:
    - `try` 阶段做资源检查和预留；`confirm` 阶段提交资源，此过程应幂等且非阻塞；`cancel` 阶段释放资源。
    - 更适合不支持事务的数据库；也可以使用这种模式。

3. **XA 模式**

**XA 模式是传统的两阶段提交协议**，Seata 提供了兼容 XA 的 API 来集成现有的 XA 数据源。

- **特点**:
    - **强一致性保证**，但是性能较低，因为需要锁定资源直到事务结束。
    - 主要用于遗留系统中已有 XA 数据源的情况。

4. **Saga 模式**

**Saga 模式是一种长事务管理模型**，适用于涉及多个服务调用的长时间运行的业务流程。

- **特点**:
    - 将整个长事务拆分为若干个补偿事务（Compensable Transactions），每个步骤都有一个正向操作和一个补偿操作。
    - 如果任何一个步骤失败，则会依次执行之前的补偿操作来回滚已经完成的操作。

#### Seata的原理

SEATA包含三个角色：TM 事务管理器，RM 资源管理器，TC 事务协调器

如果是采用 **AT**模式的话，原理大概是：

1. **全局事务开始**：**当某个业务发起一个全局事务时**，也就是标注了`@GlobalTransactional`（全局事务注解） 的那些方法，**事务管理器 会向 `事务协调器` 注册这个全局事务**，并生**成一个全局事务 ID（XID）**。所有参与这个全局事务的服务，也就是分支事务都将使用这个 XID 来标识其属于同一个事务上下文。
2. **本地事务执行**：**每个服务分支事务**作为  **资源管理器 参与到全局事务中**，**在执行本地数据库操作时**，**Seata 的 AT 模式会在 SQL 执行前后自动拦截并记录** 操作**前的数据快照** 和 **操作后的数据快照** 。这些快照用于后续的冲突检测或回滚操作。然后它就直接提交了。
3. **分支事务 提交 或者 回滚**： **资源管理器在执行本地事务后**，会**将本地事务的执行结果**（包括上述的快照信息）**上报给 事务协调器， **事务管理器在业务都执行完后发起全局事务提交或者回滚**；**`事务协调器` 检测每个分支事务的执行结果决定是提交还是回滚全局事务**。如果所有  **资源管理器RM 都上报成功**，**`事务协调器` 发出提交的指令**，也表示**全局事务成功**；如果**有任何一个 RM  资源管理器上报执行异常**，**那么`事务协调器`发出回滚指令，整个全局事务都会被回滚**。

AT模式下；**如果是全局发出提交的指令，那么分支要做的就是删除快照**；**如果是全局发出回滚的指令就根据快照回滚数据。**

如果是采用 **XA**模式的话，原理大概是：

1. **全局事务开始**：当**某个业务发起一个全局事务时**，也就是标注了`@GlobalTransactional` 的那些方法，**事务管理器会向 事务协调器注册这个全局事务**，并生成一个全局事务 ID（XID）。所有参与这个全局事务的服务，也就是分支事务都将使用这个 XID 来标识其属于同一个事务上下文。
2. **本地事务执行**：**每个服务分支事务作为 资源管理器参与到全局事务中**，在执行本地数据库操作时，**Seata 的 XA 模式会在 SQL 执行后**，**不直接提交本地事务**，**会等待事务协调器的指令进行统一的提交或者回滚。**
3. **分支事务 提交 或者 回滚**：**资源管理器 在执行本地事务后**，会**将本地事务的执行结果上报给 事务协调器**，事务管理器在业务都执行完后发起全局事务提交或者回滚；事务协调器检测每个分支事务的执行结果决定是提交还是回滚全局事务。如果所有 资源管理器都上报成功，事务协调器发出提交的指令，也表示全局事务成功，这个时候RM才真正的提交事务；如果有任何一个 RM 上报执行异常，那么TC发出回滚指令，整个全局事务都会被回滚，这个时候RM就执行回滚。

**两阶段提交（2PC）**：在AT或XA模式中，Seata采用了两阶段提交协议来保证分布式事务的一致性。

- **准备阶段**（Prepare Phase）：在这个阶段，**所有的  资源管理器 会锁定必要的资源**（XA模式才会锁定资源），**并向 事务协调器 报告它们是否准备好提交**。事务协调器 收集所有  资源管理器的准备状态。
- **提交或回滚阶段**（Commit or Rollback Phase）：**基于所有 资源管理器 的准备状态**，**事务管理器发起提交或回滚的请求**，**事务协调器决定全局事务是提交还是回滚**。如果决定**提交**，**事务协调器 会通知所有  资源管理器 提交本地事务**；如果决定**回滚**，**事务协调器 会通知所有资源管理器 回滚至最初的状态**。