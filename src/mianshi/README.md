---
icon: lightbulb
---
# 面试每日题目
### day01

#### **ES 用来做什么**

做**全文搜索**、**日志分析**、**距离计算**。和 Logstash、Kibana 组成 ELK 做日志收集、展示。

#### **为什么用 ES**

MySQL 模糊查询慢，且模糊查询时索引会失效；ES 有**分词**、**相关性搜索**、**地理位置查询**，检索速度快

#### **ES 与 MySQL 如何保持一致**

MySQL 写入 → 产生日志 binlog → Canal 监听 → 发 MQ → 搜索服务收到后写 ES。

#### **ES 数据类型有哪些**

text、keyword；integer/long/float/double/boolean；date、binary、geo_point；object 等。

#### **ES采用什么数据结构**

1. **index（索引）**
   相当于 MySQL 的“库”。不同业务放不同索引，比如 Account、Book。

2. **mapping（映射）**
   相当于“表结构”。定义字段名、字段类型、是否分词、是否可搜索。

   `type`：字段数据类型，

   `index`：是否参与搜索

   `analyzer`：构建倒排索引时使用哪种分词器分词

   `search_analyzer`: 搜索时使用哪种分词器分词

   `properties`：该字段的子字段

3. **field（字段）**
   相当于“列”。文档中的单个属性。

4. **document（文档）**

   相当于“行”。一条完整的数据记录，用 JSON 表示。

### day02

#### **使用什么分词器**

我们主要用 **IK 分词器**，包括：
**ik_max_word**：细粒度，建索引用，尽可能多切词。
**ik_smart**：粗粒度，搜索用，更贴近用户意图。

其他常见分词器：
Standard（默认英文分词）、Smart Chinese Analyzer（官方中文）、Jieba（第三方中文）。

#### 倒排索引

倒排索引是一张“词 → 文档”的映射表。每个词条都会记录：在哪些文档出现、出现次数、出现位置。搜索时 ES 会先分词，再用词条去查这张表，直接拿到文档 ID，因此速度非常快。

构建流程可以理解成“三步一落”：
先把文档切词 → 去掉无意义的停用词 → 统计词频、位置 → 最终生成“词 → 文档列表”的倒排表。

查询时的动作也很简洁：
解析用户输入 → 按关键词查倒排索引 → 给匹配文档打分（BM25 之类的相关性算法） → 按相关度排序返回。

#### 正排索引/正向索引

正排索引（Forward Index）是 **“ID → 文档内容”** 的映射。查询时要先找出文档，再把搜索词和文档内容逐个对比，看是否包含关键词，所以速度远慢于倒排索引。

#### ES的分词策略是什么

构建倒排索引时 使用ik_max_word，即 插入数据到es的时候，使用ik_max_word最细粒度；

搜索的时候 使用ik_smart 智能分词（最粗粒度）

1. 创建的时候希望更多的词条能够关联到某个文档，这样在搜索的时候更有可能被检索到
2. 搜索的时候希望更加能够贴近用户的搜索期望，而不要分词太细

#### 深度分页

针对深度分页，elasticsearch提供了两种解决方案：

- `search after`：分页时需要排序,第二次查询时候携带上一次查询的排序值作为 search_after的值就可以了；原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。
- `scroll`滚动查询：原理将排序后的文档id形成快照，保存下来，基于快照做分页。官方已经不推荐使用。

### day03

#### Redis的作用、使用场景

- 可以用作缓存
- 存放token令牌
- 发送登录时候的，短信验证码可以存放到redis
- 分布式锁

#### 常见五种数据类型及结构

string字符串，list列表，set集合，zset，hash哈希，

#### 除了常见的五种类型还有哪些

除了常见的字符串、哈希、列表、集合、有序集合外，Redis 还有：

1. **位图（Bitmaps）**：基于字符串操作的位数组，常用于统计和用户行为跟踪。
2. **超日志** **（HyperLogLog）**：概率数据结构，估算集合基数，内存占用极低。
3. **地理空间索引（Geospatial Indexes）**：存储坐标，支持距离查询（GEOADD、GEORADIUS）。
4. **流（Streams）**：消息队列结构，支持消费组和消息确认。
5. **JSON 支持**（RedisJSON 模块）：原生存储和操作 JSON 数据。

#### **缓存问题三兄弟——缓存雪崩**

**缓存雪崩**：大量缓存同时失效，导致数据库瞬时高负载。

**解决方案**：如果是宕机使用集群，如果是过期给不同缓存设置**错开过期时间**，避免集中失效。

#### 缓存问题三兄弟——**缓存穿透**（不存在的数据）

**缓存穿透**：请求不存在的数据，频繁打到数据库。
**解决方案**：

1. **布隆过滤器**：先判断数据是否存在，不存在直接拦截。
2. **缓存空结果**：把空结果缓存一段短时间，避免重复查询。

#### 缓存问题三兄弟——缓存击穿

**缓存击穿**：热点 key 过期时，大量请求直接打到数据库。
**解决方案**：

1. **加锁**：更新缓存时加锁，其他请求等待。
2. **异步预热**：提前加载热点数据到缓存。
3. **逻辑过期**：热点 key 不设置过期，到期后手动删除。

#### 布隆过滤器的实现，怎么用

**布隆过滤器**：用位图 + 多哈希函数判断元素是否存在。
**实现原理**：

- 插入：多个哈希函数计算位置，设置对应位为 1。
- 查询：检查所有对应位是否为 1；若有 0，则元素不存在；若全 1，则可能存在（有误判）

### day04

#### Redis为什么快

**全内存操作**：数据存储在内存中，访问速度极快。

**单线程架构**：避t6

**异步 I/O 多路复用**：通过 epoll 等技术高效管理大量并发连接。

#### Redis是单线程的吗

Redis 6.0之前是单线程；Redis 6.0+ 特性：

- **网络 I/O 多线程**：读写请求的网络处理可多线程加速。
- **核心命令执行仍单线程**：数据操作和命令逻辑保持单线程，保证原子性和简单锁机制。

### day05

#### Redis宕机怎么办

查看 Redis 的日志文件，通常位于 /var/log/redis/ 或通过配置指定的位置，寻找任何错误信息或警告。

**内存不足**：Redis 是内存数据库，如果内存耗尽，可能会导致 Redis 崩溃。

**配置错误**：不正确的配置可能导致 Redis 无法正常启动或运行。

**硬件故障**：如服务器硬件问题（磁盘、网络等）。

为了让redis更加可靠；我们会搭建Redis的 哨兵（3个节点） + 主从（1主2从）的方式保障其的高可用。

#### Redis有哪些集群

**主从集群**：主节点与从节点的数据是一模一样的，不能实现故障转移

**哨兵+主从**：当某个主节点宕机且哨兵的的主观下线超过一半的话就会选举新的主节点，实现了自动的故障转移，写并发能力没有提升，存储容量没有提升

**分片集群**：Redis各个集群节点的数据是不一样的，可以有多个master节点，每个master都可以提供写操作：写操作并发能力提升了

每个master还可以有多个slave，可用性更强，并且读操作并发能力也更强了

每个master存储的数据是不同，通过**CRC16算法**对数据的key做哈希计算，最终计算的结果一定是**0~16383**，增加master就增加了存储的容量

连接任意一个master，都会帮我们自动重定向到正确的master上进行存取操作

#### Redis主从复制

- `slave`节点请求增量同步
- `master`节点判断`replid`，发现不一致，拒绝增量同步
- `master`将完整内存数据生成`RDB`，发送`RDB`到`slave`
- `slave`清空本地数据，加载`master`的`RDB`
- `master`将`RDB`期间的命令记录在`repl_baklog`，并持续将log中的命令发送给`slave`
- `slave`执行接收到的命令，保持与`master`之间的同步

#### Redis数据持久化策略

Redis 提供了两种主要的数据持久化策略：RDB和 AOF

**RDB** 会将Redis内存中的数据通过快照形式持久化保存到磁盘文件上，这是一个二进制文件。默认触发快照写的策略有：

- 如果在过去900秒（15分钟）内至少有1个键发生变化，则触发一次快照。
- 如果在过去300秒（5分钟）内至少有10个键发生变化，则触发一次快照。
- 如果在过去60秒内至少有10000个键发生变化，则触发一次快照。

**AOF** 将Redis执行的 **写命令** 追加保存到**只读的日志文件**磁盘文件上 中。重启时，Redis 会重新执行这些命令以恢复数据状态。

**AOF的写回策略**：

- **每秒fsync** (`everysec`)：默认情况下，每秒一次将缓冲区的内容同步到磁盘。这种模式提供了较好的性能和安全性之间的平衡。
- **每次写入fsync** (`always`)：每次写命令都会立即同步到磁盘，确保最高的数据安全性，但会对性能产生较大影响。
- **从不fsync** (`no`)：依赖操作系统来决定何时将缓冲区内容刷新到磁盘，虽然提高了性能，但增加了数据丢失的风险。

**重写机制**：

- **AOF 重写**：为了防止 AOF 文件变得过大，Redis 支持 AOF 重写功能，即在不影响现有数据的前提下，压缩冗余的命令序列。重写过程是在**子进程中完成**的，**不会阻塞主进程**。

我们项目的话；会使用RDB和AOF混合持久化的模式；在这种模式下，AOF 文件不仅包含所有写命令，还会定期插入 RDB 快照作为基准点。这使得 AOF 文件更加紧凑，并且可以在启动时更快地加载数据。

#### 过期key处理策略

- **惰性删除**：Redis会在每次访问KEY的时候**判断当前KEY有没有设置过期时间**，如果有，过期时间是否已经到期；过期的话则删除。
- **周期删除**：通过一个定时任务，周期性的**抽样**部分过期的key，然后执行删除。

### day06

#### 内存淘汰策略

Redis支持8种不同的内存淘汰策略：

- `noeviction`： **不淘汰任何key**，但是**内存满时不允许写入新数据**，默认就是这种策略。
- `volatile-ttl`： 对**设置了TTL的key**，比较key的剩余TTL值，**TTL越小越先被淘汰**
- `allkeys-random`：对全体key ，**随机进行淘汰**。也就是直接从db->dict中随机挑选
- `volatile-random`：对设置了TTL的key ，**随机进行淘汰**。也就是从db->expires中随机挑选。
- `allkeys-lru`： 对全体key，**基于LRU算法**进行淘汰
- `volatile-lru`： 对设置了TTL的key，**基于LRU算法**进行淘汰
- `allkeys-lfu`： 对全体key，**基于LFU算法**进行淘汰
- `volatile-lfu`： 对设置了TTL的key，**基于LFU算法**进行淘汰

比较容易混淆的有两个算法：

- **LRU**（**`L`**`east`**`R`**`ecently`**`U`**`sed`），最近最久未使用。用当前时间减去最后一次访问时间，这个值越大则淘汰优先级越高。
- **LFU**（**`L`**`east`**`F`**`requently`**`U`**`sed`），最少频率使用。会统计每个key的访问频率，值越小淘汰优先级越高。

#### 分布式锁

分布式锁是一种用于在**分布式系统中保障多个进程或线程**对**共享资源正确访问的一种机制**。也就是说分布式锁要确保在不同节点或说系统上的进程不会同时访问或修改同一资源。

在redis中可以使用 `setNX + 过期时间` 的方式来实现分布式锁。

> 使用set命令也可以实现分布式锁
>
> 如果要使用set命令则： `SET key value NX PX timeout` 来尝试设置一个键，并指定超时时间（以毫秒为单位）。`NX` 表示只有当键不存在时才执行此操作，确保了锁的唯一性。PX 是 **告诉 Redis：后面这个数字的单位是毫秒**。

我们项目中使用的是**redisson实现**的，它是使用 **Redis 的** **Hash** **数据类型** 来存储和管理锁

#### 分布式锁使用场景

- 支付（**防止并发时订单的重复提交**，多次刷新导致的重复支付）
- 订单下单的时候，对商品库存进行加锁；**防止超卖**

#### Redisson的好处/优势

**1.** **分布式锁**

- Redisson 提供分布式锁功能。比如：**使用 `RLock` 可以确保分布式环境下的多个进程或者线程互斥访问资源**。

**2.** **分布式集合和数据结构**

- Redisson **提供了 Redis 支持的集合数据结构的分布式实现**，比如：
    - `RMap`（分布式 Map）
    - `RList`（分布式 List）
    - `RSet`（分布式 Set）
    - `RQueue`（分布式队列）
- **这些数据结构本身就有很好的并发性能，可以方便地在分布式系统中共享数据**。

**3.** **高可用性和故障转移**

- Redisson 能够与 Redis Sentinel 和 Redis Cluster 配合使用，支持高可用性和故障转移机制。即使 Redis 实例宕机，Redisson 可以自动重新连接到新的主节点，保证应用的持续运行。

**4.** **异步和响应式编程**

- Redisson 支持异步编程，可以通过使用 `RFuture` 和 `CompletableFuture` 提高并发性能。

**5.** **原子操作**

- Redisson 支持对 Redis 数据的原子操作，确保了操作的事务性和一致性。例如，可以在一个操作中同时执行多个 Redis 命令，而不必担心中间的竞态条件

#### Redisson看门狗

Redisson 的**看门狗**（**Watchdog**）是一个用于自动延长分布式锁过期时间的机制，**主要解决在分布式环境下，持有锁的客户端在执行任务时出现故障或崩溃的情况，防止其他客户端长时间等待锁释放。**看门狗的机制通过自动刷新（默认30秒过期时间，**每隔10秒会自动续期到30秒**，从而保持分布式锁不过期）锁的过期时间，确保锁在任务执行过程中始终保持有效。

追问：如果自动续期会不会导致一直不释放锁而产生死锁？

- 业务正常处理的话，是会释放锁的
- 如果业务不正常，我们也有异常处理，在finally里面会释放
- 如果是业务宕机，那么分布式锁也有过期时间，默认是30秒；所以怎么样都不会死锁

### day07

#### Redis如何处理并发的

通过 **单线程模型** 处理：具体

- **核心处理逻辑**：Redis 的所有读写操作都在一个单独的线程中顺序执行，避免了多线程环境下的锁竞争问题。这种设计简化了并发控制，并提高了性能。
- **非阻塞 I/O**：尽管是单线程，但 Redis 使用事件驱动的 I/O 多路复用技术（如 epoll 或 kqueue），可以同时处理大量客户端连接而不被阻塞。

#### Redis的管道

Redis管道是一种批量处理机制，它让客户端能够将多个命令打包成一个请求发送给 Redis 服务器。服务器接收到这个请求后，会依次执行这些命令并将结果一并返回给客户端。

#### Redis怎么存储一个对象

将对象序列化为 JSON 格式的字符串，然后作为普通的 Redis 字符串进行存储。

#### Redis 和数据库的数据一致性如何保证

如果要求强一致：可以采用**同步双写并加锁**的方式保证一致

如果要求最终一致：

- 方式一：可以采用**定时任务定时更新缓存**；但这种情况通常会有一段时间不一致。
- 方式二：也可以采用在**更新数据库后 直接删除缓存**
- 我们项目的门户首页里，这两种方式都用到了；更新数据时删缓存能保证**较强的一致性**，然后使用**定时任务**作为一致性的**兜底方案**

另外还有：**延迟双删**，我们项目中没有使用到（因为等待时间无法确定）

1. **第一次删除缓存**
    - 当要更新数据库时，先删缓存，防止其他请求读到旧数据。

2. **更新数据库**
    - 执行真正的数据更新操作。

3. **延时等待**

    - 等待一个短时间（比如几百毫秒到几秒），让可能同时访问缓存的请求都结束。
    - 这主要防止“数据库更新前，有请求又把旧数据写回缓存”。

4. **再次删除缓存**

- 确保缓存里没有旧数据，保证下一次读取时一定是数据库最新数据。

#### Redis的默认内存大小

Redis 的默认内存通过 **maxmemory** 设置；**大小为 64MB** 可以修改。如果超出的话，那么会抛出异常。

#### 红锁RedLock

**RedLock** 是 Redisson 提供的一种分布式锁算法，主要作用是解决**在多个 Redis 实例上执行加锁**，如果发生了单个 Redis 节点故障时仍**能保证锁的可用性和一致性**的解决方案。它的主要实现**思想是在多个 Redis 实例之间进行协作来确保锁的一致性和高可用性**。

RedLock 的实现流程如下：

1. **多个 Redis 实例**：至少需要 5 个独立的 Redis 实例部署在不同的机器或节点上，来确保高可用性。
2. **获取锁的过程**：
    1. **客户端尝试在每个 Redis 实例上获取锁。**客户端会依次向每个 Redis 节点发送请求，会尝试在每个节点上设置锁，并且记录每次请求的时间。
    2. 只有当锁在 **多数** Redis 实例（至少 3 个 Redis 节点）上成功设置，且整个过程在一个合理的时间窗口内完成时，才认为锁被成功获取。
3. **获取锁的条件**：
    1. 客户端必须在短时间内（通常是毫秒级别）向多个 Redis 节点请求并成功获得锁。
        -   这个过程需要保证：

        -   **锁的设置时间不会过长**（避免单点故障）。
        -   客户端必须**至少成功获取到大多数 Redis 节点**上的锁（通常是 3 个节点及以上）。
        -   锁的获取操作**必须具备足够的时间容忍度**。
4. **释放锁**：
    1. 客户端获取锁后，在完成任务时，客户端会从它成功获取锁的 Redis 节点上释放锁。
    2. 释放锁时，**需要检查当前客户端是不是还持有锁，避免误释放锁**。

### day08

#### SpringBoot自动装配原理

1. **启动应用**：当应用启动时，Spring Boot 会解析 `@SpringBootApplication` 注解。

> @SpringBootApplication 是一个复合注解，它包含了以下三个注解：
> @Configuration：标记当前类为配置类。
> @EnableAutoConfiguration：启用自动装配。
> @ComponentScan：扫描并注册带有 @Component 注解的类。

2. **加载配置**：`@EnableAutoConfiguration` 注解会触发自动配置机制，**加载 `spring.factories` 文件中列出的自动配置类。**
3. **条件注解**：Spring Boot 会加载 `spring.factories` 文件中每个`自动配置类`上的条件注解，**来判断是否应用这个配置**。

> 自动配置类 通常使用条件注解（如 `@ConditionalOnClass`、`@ConditionalOnMissingBean`、`@ConditionalOnProperty` 等）来控制是否应该应用某个配置。这些条件注解确保只有在满足特定条件时才会加载和应用相应的配置。

4. **应用配置**：**符合条件的自动配置类会被加载注册到IOC容器并应用**，这样实现自动配置相应的组件和服务。

> 注册到IOC容器之后；就可以在其它的Bean中通过 @Resource 或 @Autowire 注入并使用

#### Spring怎么解决循环依赖/三级缓存

Spring使用了一种称为“延迟解析”的策略来**解决循环依赖问题**。也被称为使用三级缓存来解决循环依赖问题的：

当Spring容器初始化时，它会先实例化Bean（但不会调用其初始化方法），然后将Bean放入一个临时的Map中。

**当一个Bean请求另一个Bean作为其依赖时，Spring会首先检查这个临时Map中是否有已经实例化但未完全初始化的Bean。**

如果有，就会直接返回这个Bean的引用，从而解决了循环依赖问题。

追问：三级缓存的话：

Spring 使用三级缓存机制来解决循环依赖问题。这三级缓存分别是：

1. **一级缓存（Singleton Cache）**：存放完全初始化好的单例 Bean。**(完全初始化好的 bean)**
2. **二级缓存（Early Singleton Cache）**：存放尚未完全初始化的 Bean，这些 Bean 已经完成了构造函数的调用，但还没有调用初始化方法。**(保存半成品 bean)**
3. **三级缓存（Prototype Cache）**：存放原型 Bean 的缓存，与循环依赖无关，主要用于提高原型 Bean 的创建效率。**(BeanFactory)**

#### Spring的IOC

**IOC（控制反转）**主要是用于减少代码间的耦合度。通过 IOC，对象的创建和管理**不再由程序代码直接控制**，而是交给外部容器（如 Spring 容器）来管理。这样的话，对象之间的**依赖关系可以通过配置文件或注解来声明**，而不是硬编码在程序中。

#### Spring的AOP

AOP（Aspect-Oriented Programming，面向切面编程）是一种编程范式，用于通过预定义的规则或切面对横切关注点（cross-cutting concerns）进行模块化，统一添加不同的业务逻辑。常见的应用场景包括日志记录、事务管理、安全控制、性能监控等

AOP 使得这些横切关注点与核心业务逻辑解耦，从而提高代码的可维护性、可重用性和可扩展性。

> 如果问到动态代理，则查看第一章中的动态代理实现

**核心概念**：

- 切面（Aspect）：一个模块，定义了横切关注点的实现，比如日志记录、事务管理等。切面可以包含一个或多个增强（Advice）。
- 连接点（Join Point）：程序执行过程中的一个特定点，通常是方法的调用。Spring AOP 中的连接点是方法执行时。
- 通知（Advice）：在特定的连接点执行的代码，包含了具体的横切逻辑。通知有几种类型：
    - Before：在目标方法执行之前执行。
    - After：在目标方法执行之后执行（无论方法是正常执行还是抛出异常）。
    - After-throwing：如果目标方法抛出异常时执行。
    - After-returning：如果目标方法成功返回时执行。
    - Around：在目标方法执行前后执行，可以控制目标方法的执行，甚至可以完全拦截目标方法的执行。
- 切入点（Pointcut）：定义了在哪些连接点上执行通知。切入点通过表达式来定义，比如可以指定某些方法或类上的方法需要应用通知。
- 目标对象（Target Object）：被代理的对象，通常是被 AOP 拦截的业务类。

**切面**定义“增强”，**连接点**是“可插入增强的时刻”，**通知**是“实际增强的动作”，**切入点**是“动作应用的规则”，**目标对象**是“被增强的业务”。

**切面（Aspect）**它**封装了横切逻辑**，和核心业务是分开的，**包含一个或多个增强**         `LoggingAspect` 这个类。

**连接点（Join Point）** **每个方法调用都是一个潜在的连接点**，可以插入增强逻辑。    `placeOrder()` 方法执行的这个时刻。

**通知（Advice）**它们就是**实际执行的增强操作** Before After`logBefore()` 和 `logAfter()` 方法。

**切入点（Pointcut）**它**定义了哪些方法需要应用增强逻辑的通知** `@Pointcut("execution(* com.example.demo.OrderService.*(..))")`

**目标对象（Target Object）**被代理的对象，通常是被 AOP 拦截的业务类。

```java
// 1. 目标对象（被增强的方法）
@Service
public class OrderService {

    public void placeOrder(String item) {
        System.out.println("下单成功: " + item);
    }
}

// 2. 切面（增强的方法）
@Aspect
@Component
public class LoggingAspect {

    // 切入点：所有 OrderService 的方法
    @Pointcut("execution(* com.example.demo.OrderService.*(..))")
    public void orderMethods() {}

    // 前置增强：方法执行前打印日志
    @Before("orderMethods()")
    public void logBefore(JoinPoint joinPoint) {
        System.out.println("准备调用方法: " + joinPoint.getSignature().getName());
    }

    // 后置增强：方法执行后打印日志
    @After("orderMethods()")
    public void logAfter(JoinPoint joinPoint) {
        System.out.println("方法调用完成: " + joinPoint.getSignature().getName());
    }
}

```

### day09

#### AOP失效的场景有哪些

第一类是**自我调用**。**类内部方法直接调用同类的另一个方法**，这种调用不会经过代理，自然也触发不了切面。原因是 **Spring 基于代理机制**，**只拦截代理对象的外部调用**。通常我们会**通过代码拆分**，或者使用 AspectJ 的方式解决。

第二类是**方法级别的访问权限问题**。**私有方法、静态方法**，甚至部分默认访问级别的方法，Spring AOP 都无法增强。主要原因是**私有方法无法被代理访问，静态方法属于类级别**，**也不参与实例代理**。因此在需要增强的逻辑里，我们一般会**保持方法为 public**。

第三类是**绕过代理的实例化方式**。如果业务代码里**直接 new 出对象**，**而不是通过 Spring 容器管理获取的 Bean**，那么这个对象本身就没有代理，自然不可能触发切面。整体要求是所有目标类必须交给容器管理。

第四类是**配置问题**。**切点表达式不匹配、AOP 功能未开启、依赖注入异常**，都可能导致切面逻辑不执行。通常需要检查**是否开启 AspectJ 自动代理**、**切点是否精确命中目标方法。**

Spring AOP 失效场景及其原因：

1. **自我调用问题**

    - **描述**：当一个类中的方法内部调用了同一个类的另一个被代理的方法时，AOP 代理不会拦截这个内部调用。

    - **原因**：这是因为 Spring AOP 默认使用的是基于代理的机制（JDK 动态代理或 CGLIB）。在这种情况下，只有通过代理对象进行的方法调用才会被拦截。对于同一对象内的直接方法调用，不会经过代理，因此 AOP 切面不会生效。

    - **解决方案**：可以通过重构代码来避免这种情况，例如将需要拦截的方法移到不同的类中；或者使用 AspectJ 编译时织入来处理自我调用的问题。

2. **私有方法**

    - **描述**：Spring AOP 不会拦截私有方法。

    - **原因**：由于 Java 的访问控制规则，私有方法不能被外部类（包括代理类）访问，因此 AOP 框架无法为这些方法创建代理。

    - **解决方案**：如果确实需要对私有方法应用 AOP，可以考虑将其改为受保护（`protected`）或包级私有（默认访问级别），然后再根据具体需求调整设计。

3. **静态方法**

    - **描述**：Spring AOP 也无法拦截静态方法。

    - **原因**：静态方法属于类级别的成员，不属于任何实例对象。而 Spring AOP 主要是针对对象实例的方法调用进行增强的，所以它不能应用于静态方法。

    - **解决方案**：避免在需要 AOP 增强的地方使用静态方法，或者寻找其他方式实现类似的功能。


4. **非公共方法**

    - **描述**：除了私有方法外，非公共但不是 `protected` 的方法（即默认访问级别）也可能不会被正确拦截。

    - **原因**：这取决于具体的代理机制。JDK 动态代理只支持公共接口的方法，而 CGLIB 代理则可以处理更多类型的方法，但仍有一些限制。

    - **解决方案**：尽量确保需要 AOP 增强的方法是公开的（`public`），以保证兼容性。

5. **绕过代理**

    - **描述**：如果直接通过 `new` 关键字创建了一个目标对象而不是通过 Spring 容器获取，则这个对象不会被 AOP 代理所包装，因此其上的 AOP 切面也不会生效。

    - **原因**：Spring AOP 是基于 Spring 容器管理的对象（Bean）工作的。只有那些由容器创建和管理的对象才会受到 AOP 规则的影响。


- **解决方案**：始终从 Spring 应用上下文中获取 Bean 实例，而不是自行实例化它们。


6. **错误配置**

    - **描述**：如果 AOP 配置不正确，例如切入点表达式写错、缺少必要的依赖注入等，也会导致 AOP 不起作用。

    - **原因**：配置错误会导致 Spring 无法正确识别哪些方法应该被增强，或者根本就没有启动 AOP 支持。


- **解决方案**：仔细检查 AOP 配置文件（XML 或注解），确保所有设置都是准确无误的，并且已经启用了 AOP 支持（例如通过 `<aop:aspectj-autoproxy/>` 或 `@EnableAspectJAutoProxy` 注解）。


#### 事务的传播行为

在 Spring 的事务传播机制里，**核心思想就是**——**当一个方法被事务管理时，另一个方法再调用它，这两个事务之间该怎么协作**。Spring 一共提供了七种传播行为，我重点按语义来讲。

首先是需要有事务(默认)。它的策略是“**有事务就加入，没有就自己开一个**”。这个适用于大多数情况。

第二类是支持事务，可有可无的。**有事务会加入，如果没有，它就直接以非事务方式运行。**常**用于读操作**，对一致性要求不高。

第三类必须要有事务，没有就抛出异常，**有事务会加入；如果当前没有事务，则抛出异常**。通常用于必须依赖事务上下文的逻辑。

第四个是起一个新事务创建一个新的事务，**如果当前存在事务，则将当前事务挂起**，适用于那些需要独立事务的操作

第五个不需事务内运行，有则挂起，**以非事务方式执行操作，如果当前存在事务，则将当前事务挂起**，适用于那些不应该在事务中执行的操作

第六个是非事务方式执行，**以非事务方式执行操作，如果当前存在事务，则抛出异常**，适用于那些绝对不能在事务中执行的操作

第七个是嵌套事务，**如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则创建一个新的事务**。用于那些需要在一个更大的事务中执行部分操作

Spring 定义了七种主要的事务传播行为：

1. **REQUIRED-需要有事务**（默认）
    - **描述**：如果当前存在事务，则加入这个事务；如果当前没有事务，则创建一个新的事务。
    - **适用场景**：最常见的场景，适用于大多数情况。
2. **SUPPORTS-支持事务，可有可无**
    - **描述**：如果当前存在事务，则加入这个事务；如果当前没有事务，则以非事务方式执行。
    - **适用场景**：适用于那些不需要事务支持的操作，但如果存在事务也不会影响结果的情况。
3. **MANDATORY-必须要有事务，没有就抛出异常**
    - **描述**：如果当前存在事务，则加入这个事务；如果当前没有事务，则抛出异常。
    - **适用场景**：适用于那些必须在事务中执行的操作，如果不在事务中执行则会失败。
4. **REQUIRES_NEW-起一个新事务**
    - **描述**：创建一个新的事务，如果当前存在事务，则将当前事务挂起。
    - **适用场景**：适用于那些需要独立事务的操作，即使在已有事务中也需要创建新的事务。
5. **NOT_SUPPORTED-不需事务内运行，有则挂起**
    - **描述**：以非事务方式执行操作，如果当前存在事务，则将当前事务挂起。
    - **适用场景**：适用于那些不应该在事务中执行的操作，例如查询数据库状态的操作。
6. **NEVER-非事务方式执行**
    - **描述**：以非事务方式执行操作，如果当前存在事务，则抛出异常。
    - **适用场景**：适用于那些绝对不能在事务中执行的操作。
7. **NESTED-嵌套事务**
    - **描述**：如果当前存在事务，则在嵌套事务内执行；如果当前没有事务，则创建一个新的事务。
    - **适用场景**：适用于那些需要在一个更大的事务中执行部分操作，但这些操作可以独立回滚的情况。

#### Spring事务失效

1. **在类里面**，使用没有事务控制的方法 调用有事务控制的方法：
    - **总结**：内部方法调用不会触发事务管理，因为事务管理是基于代理的。
2. 在事务控制的方法内部，如果将**异常捕获而且不抛出**的话；不会进行正常的回滚，也属于事务失效
    - **总结**：捕获异常但不重新抛出会阻止事务管理器检测到异常并回滚事务。
3. 事务方法**不是使用public 修饰符**的话，也会导致事务失效：
    - **总结**：`@Transactional` 注解只能作用于 public 方法。
4. 如果调用事务方法的实例；是**使用了 `new` 关键字手动创建的**，也会导致事务失效：
    - **总结**：**手动创建 Bean 会绕过 Spring 容器**，导致事务管理失效。
5. **使用了错误的事务传播行为**：
    - **总结**：某些事务传播行为（如 `NOT_SUPPORTED`、`NEVER`）会禁用事务管理。

#### Spring中Bean的加载流程

**首先是读取和解析配置文件**，**接下来框架会准备一个 BeanFactory**，这是整个 IoC 的核心，用来管理 Bean 的创建和生命周期。

配置读完之后，会**把每个 Bean 的元信息**，**也就是 BeanDefinition**，**注册到容器里**，但此时 Bean 还没有真正实例化。紧接着调用**BeanFactoryPostProcessor**。这类处理器允许在 Bean 实例化之前，对 BeanDefinition 做修改

**随后才进入真正的 Bean 创建阶段**。**Spring 会根据 BeanDefinition 去实例化对象**，并在**实例化后设置 Bean 的属性值**，然后调用**BeanPostProcessor**，它允许开发者在初始化前后做增强，比如 AOP 的代理就是在这里生成的。

然后是**调用初始化方法**。到这一步，Bean 才算完全就绪，可以被容器使用和注入。

最后，**在容器关闭时**，**会调用销毁方法**，对资源进行清理。

Spring 中 Bean 的加载流程可以概括为以下几个主要步骤：

1. **读取配置**：读取和解析配置文件。
2. **创建 BeanFactory**：创建 `BeanFactory`。
3. **注册 BeanDefinition**：注册 Bean 定义。
4. **初始化 BeanFactoryPostProcessors**：调用 `BeanFactoryPostProcessor`。
5. **实例化 Bean**：创建 Bean 实例。
6. **设置属性值**：设置 Bean 的属性值。
7. **初始化 BeanPostProcessors**：调用 `BeanPostProcessor`。
8. **调用初始化方法**：调用初始化方法。
9. **使用 Bean**：Bean 初始化完成后可以被使用。
10. **销毁 Bean**：容器关闭时调用销毁方法。

### day10

#### RabbitMQ在哪用到了/场景

用户在**小程序里搜索服务**时，**需要提前将服务信息同步到ES**，用到了RabbitMQ

**历史订单的冷热分离**时，将**完成15日的订单迁移到历史订单库**时，用到了RabbitMQ

**订单过期时自动取消订单**，用到了RabbitMQ的延迟消息

**支付服务向业务服务通知支付结果时**

#### 消息重复消费/幂等

1、**发送消息的时候，携带消息Id**；

2、**消费者接收消息**的时候，**先根据消息id到数据库**（mysql，redis都可以）中的 **去重表**（`主键、消息id、消息内容，接收时间，处理时间，处理状态`） **查询是否已经处理过这个消息**；

3、**如果处理过这个消息则什么都不做**，避免重复处理；

4、**如果没有这个消息说明还没处理过**，**保存消息到去重表 ；然后再处理消息**；**如果处理消息成功则更新去重表的状态为1**；**如果处理失败则可以采用定时任务**，定时对这个消息进行处理，**直到处理消息成功为止**。

#### 消息怎么可靠生产

我们会在**发送消息的时候**，**开启生产者重连机制**；并且**使用Confirm回调**和**Return回调**处理发送失败的消息，将失败消息记录到一张表里面；**启动定时任务**定时发送，**发送到成功为止**

**定时任务怎么做？**：

1. 首先**把消息数据写入数据库**，用**状态码来控制消息发送状态**。
2. **开启定时任务**，间隔时间比如3秒，**查询未发送的消息**。
3. **调用消息生产者**，**发送消息到MQ中间件**。
4. **消息生产者**，**设置confirmCallback确认回调对象**，**判断ack**

-- true:  消息发送成功，**修改消息发送状态为: 已发送**。

-- false: 消息发送失败。

#### 消息怎么可靠的消费

1、**消费者确认机制**；接收的时候，业务处理成功才返回ack

2、也会设置**消费者本地重试机制**；比如：在消费者端配置重试3次

3、如果**重试也失败的话**，就**按照消息回收策略**，**将消息重新发布到其它交换机**

4、如果**再不行**；那**就主动反向查询业务**，**在生产者这边直接查询消费者端的业务处理成功没有**（兜底方案）

#### RabbitMQ自身可靠

**所有的交换机、队列、消息都可以设置为持久化模式**（重启后还在）

**RabbitMQ可以做集群**，**实现镜像队列和仲裁队列**（即使RabbitMQ其中一个节点挂了；也还有其它节点提供服务；不仅如此，因为做了镜像或仲裁队列，所以交换机、队列、消息也都是不会丢失的，每个节点都会有副本。）

![图片1](./assets/image-20251127221302834-1764317814553-1.png)

### day11

#### 消息积压/堆积问题

1. **消息过多，消费者消费速度太慢。那么可以**
   - **增加多个消费者并发**消费
   - **每个消费者中使用多线程**并发消费
   - **设置消息存活时间(TTL)** Time To Live
   - **设置队列中存储消息的界限**(Lim) limit

2. **消费者消费失败，消息还在业务队列中。**
   - 再重试一次，如果**还不行，扔到死信队列，避免队列阻塞**。

#### 死信队列

当我们的**业务队列处理消息失败**(业务异常**重试次数达到上限**、**消息被拒绝**、**消息过期**、**队列已满**)，就会**将这些消息重新投递到一个新的队列**，**这个队列存储的都是处理失败的消息**，这个队列**就叫死信队列DLQ**(Dead Letter Queue)。

什么是死信？或者说为什么叫死信？因为这些消息大概是因为：

- **消息发送的时候被拒绝** (basic.reject or basic.nack)
- 或者 **消息过期 TTL**(Time To Live)
- 也可能是 **队列已满 消息进不了队列**；那这**些消息都被称为死信**

使用场景：只要是需要**发送延迟消息的地方都可以使用死信队列实现**；如：**清理垃圾附件、超时取消合同、超时支付**等

#### MQ的工作模式和交换机类型、核心概念

**MQ的工作模式**：简单队列模式、工作队列模式、fanout广播交换机、direct定向交换机、topic主题交换机、【headers请求头交换机交换机】

**核心概念**：连接Connection、通道Channel、交换机Exchange、队列Queue、绑定binding、消息Message

#### RabbitMQ的队列类型

临时队列、持久化队列、延时队列、死信队列、镜像队列、仲裁队列

#### RabbitMQ 中实现顺序消费消息

1、**基于单个队列+单线程消费实现顺序消费**

- **单队列模型：** 最直接的方式是使用一个队列来保证消息顺序。RabbitMQ 会按照生产者发送消息的顺序，将消息逐个传递给消费者。消费者使用单线程处理，会按照队列中的顺序来消费这些消息。确保消费者一个接一个地消费消息就可以保证顺序消费。

2、**使用消息的唯一标识符和分区**

如果有多组消息需要按顺序消费，但这些消息是独立的（例如：每组消息对应某个特定的用户、订单或其他对象），可以根据消息的分区键（例如：用户ID、订单ID等）将消息路由到不同的队列。

3、**配置** **`prefetch`** **参数**

在 RabbitMQ 中，`prefetch` 使得每个消费者一次只处理一个消息，从而保证了消息的顺序性。